# RWKV è¯„ä¼°æ¡†æ¶

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ RWKV æ¨¡å‹è¯„ä¼°æ¡†æ¶ï¼Œæ”¯æŒæœ¬åœ°æ‰¹é‡è¯„ä¼°å’Œ API è¯„ä¼°ä¸¤ç§æ¨¡å¼ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
rwkveval/
â”œâ”€â”€ local_batch_benchmark/      # ğŸš€ æœ¬åœ°æ‰¹é‡è¯„ä¼°ï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰
â”‚   â”œâ”€â”€ tasks/                 # æ•°æ®é›†æ³¨å†Œæ¨¡å—ï¼ˆåŸ datasets/ï¼‰
â”‚   â”‚   â”œâ”€â”€ dataset_registry.py
â”‚   â”‚   â””â”€â”€ register_*.py
â”‚   â”œâ”€â”€ evaluators/            # è¯„ä¼°å™¨æ³¨å†Œæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ evaluator_registry.py
â”‚   â”‚   â””â”€â”€ register_*.py
â”‚   â”œâ”€â”€ batch_engine.py        # RWKVæ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ pipeline.py           # è¯„ä¼°ç®¡çº¿
â”‚   â”œâ”€â”€ run_pipeline.py       # é€šç”¨å‘½ä»¤è¡Œå…¥å£
â”‚   â”œâ”€â”€ run_mmlu_pro.py       # MMLU Proä¸“ç”¨è„šæœ¬
â”‚   â”œâ”€â”€ example_usage.py      # Python APIä½¿ç”¨ç¤ºä¾‹
â”‚   â””â”€â”€ README.md             # è¯¦ç»†æ–‡æ¡£
â”‚
â”œâ”€â”€ api_benchmark/             # ğŸŒ APIè¯„ä¼°ï¼ˆç”¨äºé›†æˆlm_evalç­‰å·¥å…·ï¼‰
â”‚   â”œâ”€â”€ api_server.py         # FastAPIæœåŠ¡å™¨
â”‚   â”œâ”€â”€ api.sh                # å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ batch_engine.py       # RWKVæ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ run_eval.sh           # lm_evalè¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ test_lambada_api.py   # APIæµ‹è¯•
â”‚
â”œâ”€â”€ benchmarkdata/             # è¯„ä¼°æ•°æ®é›†
â”‚   â”œâ”€â”€ mmlupro/              # MMLU Proæ•°æ®
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ reference/                 # RWKVæ¨¡å‹å‚è€ƒå®ç°
â”‚   â”œâ”€â”€ rwkv7.py              # RWKV-7æ¨¡å‹
â”‚   â””â”€â”€ utils.py              # Tokenizerç­‰å·¥å…·
â”‚
â”œâ”€â”€ tools/                     # å·¥å…·è„šæœ¬
â”‚   â””â”€â”€ download.sh           # æ•°æ®é›†ä¸‹è½½è„šæœ¬
â”‚
â””â”€â”€ README.md                  # æœ¬æ–‡ä»¶
```

## ğŸ¯ ä¸¤ç§è¯„ä¼°æ¨¡å¼å¯¹æ¯”

| ç‰¹æ€§ | æœ¬åœ°æ‰¹é‡è¯„ä¼° | APIè¯„ä¼° |
|------|------------|---------|
| **ç›®å½•** | `local_batch_benchmark/` | `api_benchmark/` |
| **è¿è¡Œæ–¹å¼** | ç›´æ¥è°ƒç”¨æ¨ç†å¼•æ“ | é€šè¿‡HTTP API |
| **é€‚ç”¨åœºæ™¯** | â€¢ å¿«é€Ÿè¿­ä»£å¼€å‘<br>â€¢ æ·»åŠ æ–°æ•°æ®é›†<br>â€¢ è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘ | â€¢ ä¸å¤–éƒ¨å·¥å…·é›†æˆ<br>â€¢ lm_evalæµ‹è¯„<br>â€¢ æ ‡å‡†åŒ–APIæ¥å£ |
| **æ€§èƒ½** | âš¡ æ›´å¿«ï¼ˆæ— ç½‘ç»œå¼€é”€ï¼‰ | ğŸŒ ç¨æ…¢ï¼ˆæœ‰HTTPå¼€é”€ï¼‰ |
| **çµæ´»æ€§** | ğŸ”§ é«˜ï¼ˆå®Œå…¨æ§åˆ¶ï¼‰ | ğŸ“¦ ä¸­ï¼ˆæ ‡å‡†åŒ–æ¥å£ï¼‰ |
| **æ‰©å±•æ€§** | âœ… æ¨¡å—åŒ–æ³¨å†Œç³»ç»Ÿ | âœ… OpenAIå…¼å®¹API |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1: æœ¬åœ°æ‰¹é‡è¯„ä¼°ï¼ˆæ¨èï¼‰

```bash
cd local_batch_benchmark

# 1. æŸ¥çœ‹å¯ç”¨ç»„ä»¶
python3 run_pipeline.py --list

# 2. è¿è¡Œ MMLU Pro è¯„ä¼°ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python3 run_mmlu_pro.py \
    --dataset-path /home/rwkv/Peter/rwkveval/benchmarkdata/mmlupro \
    --batch-size 64 \
    --limit 100

# 3. è¿è¡Œå®Œæ•´ MMLU Pro è¯„ä¼° + ä¿å­˜æ¨ç†ç»“æœ
python3 run_mmlu_pro.py \
    --dataset-path /home/rwkv/Peter/rwkveval/benchmarkdata/mmlupro \
    --batch-size 64 \
    --inferoutput ./results/mmlu_pro_predictions.jsonl

# 4. è¿è¡Œ LAMBADA è¯„ä¼°
python3 run_pipeline.py \
    --dataset lambada \
    --dataset-path /path/to/lambada_test.jsonl \
    --evaluator perplexity \
    --batch-size 256 \
    --limit 500
```

**é‡è¦å‚æ•°è¯´æ˜ï¼š**
- `--limit N`: åªæµ‹è¯•å‰ N ä¸ªæ ·æœ¬ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
- `--inferoutput PATH`: ä¿å­˜æ¯ä¸ªæ ·æœ¬çš„æ¨ç†ç»“æœåˆ° JSONL æ–‡ä»¶
- `--batch-size N`: è°ƒæ•´æ‰¹å¤„ç†å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜ï¼‰
- `--cot`: ä½¿ç”¨ Chain-of-Thoughtï¼ˆé’ˆå¯¹ MMLU-Proï¼‰

### æ–¹å¼2: API è¯„ä¼°

```bash
cd api_benchmark

# 1. å¯åŠ¨ API æœåŠ¡å™¨
./api.sh

# 2. è¿è¡Œ lm_eval è¯„ä¼°ï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰
./run_eval.sh
```

---

## ğŸ“š æœ¬åœ°æ‰¹é‡è¯„ä¼° - è¯¦ç»†è¯´æ˜

### æ·»åŠ æ–°æ•°æ®é›†

1. **åˆ›å»ºæ•°æ®é›†æ³¨å†Œæ–‡ä»¶** `local_batch_benchmark/tasks/register_your_dataset.py`:

```python
from .dataset_registry import DatasetRegistry
import json

def load_your_dataset(path: str):
    with open(path, 'r') as f:
        return json.load(f)

def your_prompt_template(item: dict) -> str:
    return f"Question: {item['question']}\nAnswer:"

DatasetRegistry.register(
    name='your_dataset',
    loader=load_your_dataset,
    prompt_template=your_prompt_template,
    description='Your dataset',
    default_batch_size=128,
    default_max_length=100
)
```

2. **åœ¨ `tasks/__init__.py` ä¸­å¯¼å…¥**:

```python
from . import register_your_dataset
```

3. **ä½¿ç”¨**:

```bash
python3 run_pipeline.py \
    --dataset your_dataset \
    --dataset-path /path/to/data.json \
    --evaluator generation
```

### å†…ç½®æ•°æ®é›†

| æ•°æ®é›† | æè¿° | è¯„ä¼°å™¨ |
|--------|------|--------|
| `lambada` | LAMBADAè¯­è¨€å»ºæ¨¡ | `perplexity` |
| `mmlu_pro` | MMLU Proå¤šé€‰é¢˜ | `mmlu_pro` |
| `qa` | é€šç”¨é—®ç­” | `exact_match` |
| `completion` | æ–‡æœ¬è¡¥å…¨ | `generation` |
| `cot` | Chain-of-Thought | `generation` |
| `math` | æ•°å­¦é—®é¢˜ | `generation` |

### å†…ç½®è¯„ä¼°å™¨

| è¯„ä¼°å™¨ | æè¿° | æŒ‡æ ‡ |
|--------|------|------|
| `perplexity` | å›°æƒ‘åº¦å’Œå‡†ç¡®ç‡ | perplexity, accuracy |
| `exact_match` | ç²¾ç¡®åŒ¹é… | accuracy |
| `generation` | ç”Ÿæˆç»Ÿè®¡ | throughput, tokens |
| `mmlu_pro` | MMLUå¤šé€‰é¢˜ | accuracy, subject_acc |

---

## ğŸŒ API è¯„ä¼° - è¯¦ç»†è¯´æ˜

### å¯åŠ¨ API æœåŠ¡å™¨

ç¼–è¾‘ `api_benchmark/api.sh` é…ç½®å‚æ•°ï¼š

```bash
python api_server.py \
    --host 192.168.0.82 \
    --port 8000 \
    --llm_path /path/to/model \
    --batch_size 128 \
    --max_tokens 2048
```

ç„¶åè¿è¡Œï¼š
```bash
cd api_benchmark
./api.sh
```

### ä½¿ç”¨ lm_eval è¯„ä¼°

ç¼–è¾‘ `api_benchmark/run_eval.sh`ï¼š

```bash
export OPENAI_API_KEY="EMPTY"
export OPENAI_API_BASE="http://192.168.0.82:8000/v1"

lm_eval --model openai-completions \
    --model_args base_url="http://192.168.0.82:8000/v1/completions",model=davinci-002,tokenized_requests=false \
    --tasks lambada_openai \
    --output_path ./eval_results
```

ç„¶åè¿è¡Œï¼š
```bash
./run_eval.sh
```

### API ç«¯ç‚¹

| ç«¯ç‚¹ | æè¿° |
|------|------|
| `POST /v1/completions` | æ–‡æœ¬è¡¥å…¨ï¼ˆæ”¯æŒlogprobsï¼‰ |
| `POST /v1/chat/completions` | èŠå¤©å¯¹è¯ |
| `GET /v1/models` | åˆ—å‡ºæ¨¡å‹ |
| `GET /health` | å¥åº·æ£€æŸ¥ |
| `GET /stats` | ç»Ÿè®¡ä¿¡æ¯ |

---

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### å¼€å‘é˜¶æ®µ
âœ… ä½¿ç”¨ **æœ¬åœ°æ‰¹é‡è¯„ä¼°** (`local_batch_benchmark/`)
- å¿«é€Ÿè¿­ä»£
- æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†
- è°ƒè¯•è¯„ä¼°é€»è¾‘

### ç”Ÿäº§/é›†æˆé˜¶æ®µ
âœ… ä½¿ç”¨ **API è¯„ä¼°** (`api_benchmark/`)
- ä¸ lm_eval é›†æˆ
- æ ‡å‡†åŒ–è¯„ä¼°æµç¨‹
- å¤šå®¢æˆ·ç«¯è®¿é—®

---

## ğŸ“– æ–‡æ¡£

### æœ¬åœ°æ‰¹é‡è¯„ä¼°
- ğŸ“˜ `local_batch_benchmark/README.md` - å®Œæ•´æ–‡æ¡£
- ğŸš€ `local_batch_benchmark/QUICK_START.md` - å¿«é€Ÿå¼€å§‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
- ğŸ“ `local_batch_benchmark/HOW_TO_ADD_NEW_DATASET.md` - æ·»åŠ æ•°æ®é›†æ•™ç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

### API è¯„ä¼°
- ğŸ“˜ `api_benchmark/README.md` - APIæ–‡æ¡£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

---

## ğŸ¯ å…¸å‹å·¥ä½œæµç¨‹

### åœºæ™¯1: æ·»åŠ æ–°çš„è¯„æµ‹ä»»åŠ¡

1. åœ¨ `local_batch_benchmark/datasets/` åˆ›å»ºæ•°æ®é›†æ³¨å†Œ
2. ï¼ˆå¯é€‰ï¼‰åœ¨ `local_batch_benchmark/evaluators/` åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°å™¨
3. åœ¨ `datasets/__init__.py` å’Œ `evaluators/__init__.py` ä¸­å¯¼å…¥
4. ä½¿ç”¨ `run_pipeline.py` è¿è¡Œè¯„ä¼°
5. éªŒè¯ç»“æœåï¼Œå¯é€šè¿‡ API æ¨¡å¼é›†æˆåˆ° lm_eval

### åœºæ™¯2: è¿è¡Œæ ‡å‡†è¯„æµ‹

1. ç›´æ¥ä½¿ç”¨ `local_batch_benchmark/run_pipeline.py`
2. æˆ–è€…ä½¿ç”¨ `api_benchmark/run_eval.sh` é€šè¿‡ lm_eval

### åœºæ™¯3: å¤§è§„æ¨¡è¯„æµ‹

1. å¯åŠ¨ API æœåŠ¡å™¨ (`api_benchmark/api.sh`)
2. ä½¿ç”¨ lm_eval æˆ–å…¶ä»–å·¥å…·è¿æ¥ API
3. å¹¶å‘è¯„ä¼°å¤šä¸ªä»»åŠ¡

---

## ğŸ”§ ç¯å¢ƒé…ç½®

```bash
# è®¾ç½®æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
export MODEL_PATH="/home/rwkv/models/rwkv7/rwkv7-g1-0.4b-20250324-ctx4096"

# HuggingFace é…ç½®ï¼ˆç”¨äºä¸‹è½½æ•°æ®é›†ï¼‰
export HF_TOKEN="your_token"
export HF_HOME="~/.cache/huggingface"
export HF_ENDPOINT="https://hf-mirror.com"
```

---

## ğŸ“Š ç»“æœè¾“å‡º

### æœ¬åœ°æ‰¹é‡è¯„ä¼°
ç»“æœä¿å­˜åœ¨ `local_batch_benchmark/eval_results/`:
```
eval_results/
â”œâ”€â”€ lambada_perplexity_20241016_123456.json
â”œâ”€â”€ mmlu_pro_mmlu_pro_20241016_123500.json
â””â”€â”€ summary_20241016_123600.json
```

### API è¯„ä¼°
lm_eval ç»“æœä¿å­˜åœ¨ `api_benchmark/eval_results/` æˆ–æŒ‡å®šçš„è¾“å‡ºç›®å½•

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æ·»åŠ æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°å™¨ï¼

1. Fork é¡¹ç›®
2. åœ¨ `local_batch_benchmark/datasets/` æˆ– `local_batch_benchmark/evaluators/` æ·»åŠ æ³¨å†Œæ–‡ä»¶
3. æ›´æ–° `__init__.py`
4. æäº¤ Pull Request

---

## ğŸ“® è”ç³»

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹å„ç›®å½•ä¸‹çš„ README.md æˆ–æissueã€‚

