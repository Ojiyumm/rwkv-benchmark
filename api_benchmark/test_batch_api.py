#!/usr/bin/env python3
"""
æµ‹è¯•ä¸¤ç§ Batch æ¨¡å¼çš„æ€§èƒ½
"""

import requests
import time
import asyncio
import aiohttp


API_URL = "http://localhost:8001"


def test_batch_endpoint(prompts, max_tokens=20):
    """æµ‹è¯• Batch Endpointï¼ˆæ–¹æ¡ˆ1ï¼Œæœ€å¿«ï¼‰"""
    print(f"\n{'='*60}")
    print("æµ‹è¯• Batch Endpoint")
    print(f"{'='*60}")
    
    start = time.time()
    response = requests.post(
        f"{API_URL}/v1/batch/completions",
        json={
            "prompts": prompts,
            "max_tokens": max_tokens
        },
        timeout=300
    )
    elapsed = time.time() - start
    
    if response.status_code == 200:
        result = response.json()
        print(f"âœ… æˆåŠŸ")
        print(f"   Batch Size: {result['batch_size']}")
        print(f"   æ¨ç†æ—¶é—´: {result['inference_time']:.3f}s")
        print(f"   æ€»æ—¶é—´: {elapsed:.3f}s")
        if result.get('speed_stats'):
            stats = result['speed_stats']
            print(f"   é€Ÿåº¦: forward {stats['forward_tps']:.2f} tok/s, full {stats['full_tps']:.2f} tok/s")
        print(f"   ç»“æœç¤ºä¾‹: {result['results'][0][:50]}...")
        return result['results'], elapsed
    else:
        print(f"âŒ å¤±è´¥: {response.text}")
        return None, elapsed


async def test_dynamic_batching(prompts, max_tokens=20):
    """æµ‹è¯• Dynamic Batchingï¼ˆæ–¹æ¡ˆ2ï¼‰"""
    print(f"\n{'='*60}")
    print("æµ‹è¯• Dynamic Batching")
    print(f"{'='*60}")
    
    async def single_request(session, prompt):
        async with session.post(
            f"{API_URL}/v1/completions",
            json={
                "prompt": prompt,
                "max_tokens": max_tokens
            },
            timeout=aiohttp.ClientTimeout(total=300)
        ) as response:
            result = await response.json()
            return result["choices"][0]["text"]
    
    start = time.time()
    async with aiohttp.ClientSession() as session:
        tasks = [single_request(session, p) for p in prompts]
        results = await asyncio.gather(*tasks)
    elapsed = time.time() - start
    
    print(f"âœ… æˆåŠŸ")
    print(f"   Batch Size: {len(prompts)}")
    print(f"   æ€»æ—¶é—´: {elapsed:.3f}s")
    print(f"   ç»“æœç¤ºä¾‹: {results[0][:50]}...")
    
    return results, elapsed


def main():
    # æµ‹è¯•æ•°æ®
    prompts = [
        "The capital of France is",
        "1+1=",
        "Today is",
        "Hello world",
    ] * 32  # 128ä¸ªè¯·æ±‚
    
    print(f"\n{'='*80}")
    print(f"API Batch æ€§èƒ½æµ‹è¯•")
    print(f"{'='*80}")
    print(f"API URL: {API_URL}")
    print(f"æµ‹è¯•è¯·æ±‚æ•°: {len(prompts)}")
    print(f"{'='*80}")
    
    # æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
    try:
        response = requests.get(f"{API_URL}/stats")
        stats = response.json()
        print(f"\næœåŠ¡å™¨çŠ¶æ€:")
        print(f"  æ¨¡å¼: {stats['batch_mode']}")
        print(f"  çŠ¶æ€: {stats['status']}")
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
        return
    
    # æµ‹è¯•1: Batch Endpoint
    results1, time1 = test_batch_endpoint(prompts, max_tokens=20)
    
    # æµ‹è¯•2: Dynamic Batching (å¦‚æœå¯ç”¨)
    if stats['batch_mode'] == 'dynamic_batching':
        results2, time2 = asyncio.run(test_dynamic_batching(prompts, max_tokens=20))
        
        print(f"\n{'='*60}")
        print("æ€§èƒ½å¯¹æ¯”")
        print(f"{'='*60}")
        print(f"Batch Endpoint:    {time1:.3f}s  â† æ›´å¿«ï¼")
        print(f"Dynamic Batching:  {time2:.3f}s")
        print(f"å·®è·:              {time2-time1:.3f}s ({(time2/time1-1)*100:.1f}%)")
    else:
        print(f"\nğŸ’¡ æç¤º: å½“å‰æœåŠ¡å™¨ä½¿ç”¨ Batch Endpoint æ¨¡å¼")
        print(f"   è¦æµ‹è¯• Dynamic Batchingï¼Œé‡å¯æœåŠ¡å™¨æ—¶åŠ ä¸Š: --batch_mode dynamic")
    
    print(f"\n{'='*80}")
    print("æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()

